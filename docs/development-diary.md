## 3.11

- Improve authenticated scraping #22
- Optimize the agent(s) #23

Not yet completed due to challenges, but getting there:

- 2 phase processing for urls #12
- Crawling along different next page links #13

What is planned next:

- Alternative extract mode #27
- Testing basic functionality on different sites #28
- Testing auth scraping #29

## 27.10

- Experiement with subagent #11
- Setup the pipeline #15
- Authenticated scraping #14

Not yet completed due to challenges, but getting there:

- 2 phase processing for urls #12
- Crawling along different next page links #13

What is planned next:

- Improve authenticated scraping #22
- Optimize the agent(s) #23

## 20.10

Autumn break

## 13.10

- Init agent to handle spider data #3
- Test and integrate #8

What is planned next:

- Experiement with subagent #11
- 2 phase processing for urls #12
- Crawling along different next page links #13
- Authenticated scraping #14
- Setup the pipeline #15

## 6.10

- Init spiders #1
- Extension: capturing urls #6
- Extension: Validate and send #7

What is planned next:

- Init agent to handle spider data #3
- Test and integrate #8

## 29.9

- Setup the project backend (Python+FastAPI) #2
- Setup extension WXT (React+TS) #5
- Experiment with spiders
- Experiment with agents

What is planned next:

- Init spiders #1
- Init agent to handle spider data #3
- Extension: capturing urls #6
- Extension: Validate and send #7
- Test and integrate #8